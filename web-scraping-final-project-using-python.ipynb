{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Scraping the Full Time Jobs on Apna .com**\n",
    "\n",
    "![](https://i.imgur.com/6o1URlU.png)\n",
    "\n",
    "* **Scraping :- Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.**\n",
    "\n",
    "* **https://apna.co/jobs/ is a job consult website from you can get information about job vacancies in many companies. Here you can apply for job according to your profession, location,companies,qualification.On the site you can easily see the about job title, company name,location of office and salary which is company offered.**\n",
    "\n",
    "* **we will scrape https://apna.co/jobs/ to get the details of jobs like their Jobs-Title,Company-Name,Location, and Salary using python libraries [requests](https://datagy.io/python-requests/) and [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/) Then we will fetch the data in .CSV format using Pandas Library for further analysis.**\n",
    "\n",
    "* **Outline of the steps we will follow:-**\n",
    "1. **download the web-page using 'Requests'.**\n",
    "2. **Parse the HTML Source code using 'BeautifulSoup'.**\n",
    "3. **Extract the Job-Title,Company-Name,Location,Salary from the web-page.**\n",
    "4. **Complile the extracted information into python lists and Dictionaries.**\n",
    "5. **Extract and combine data from multiple pages.**\n",
    "6. **Save the Extracted information into .CSV format**\n",
    "\n",
    "* **At the end of the project we will create the csv file in the following format**\n",
    "```\n",
    "  Job-Name, Company, Location, Salary\n",
    "  Business Head, Kalandoor Entertainments Private Limited,Elamakkara, ₹1,00,000 - ₹1,49,999............................................**\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Run code\n",
    "\n",
    "You can execute the code using \"Run\" buttom at the top of this page and selecting \"Run on Binder\". \n",
    "you can make changes and save your own version of notebook to [jovian](https://jovian.com/) by executing the cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* firstly we need to install and import the library to download the webpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --upgrade --quiet\n",
    "!pip install BeautifulSoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://apna.co/jobs/full_time-jobs?page=1&work_type=full_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using variable to get the webpage\n",
    "response=requests.get(url,headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the status code of the downloaded page\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220032"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the length of words \n",
    "len(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content=response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html lang=\"en\"><head><meta charSet=\"utf-8\"/><link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/apple-touch-icon.png\"/><link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"/favicon-32x32.png\"/><link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"/favicon-16x16.png\"/><link rel=\"manifest\" href=\"/site.webmanifest\"/><link rel=\"preconnect\" href=\"https://cdn.apna.co\"/><meta name=\"theme-color\" content=\"#4d3951\"/><meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\"/><title>Full Time Jobs – Find 24,731 Full Time Job Vacancies  | apna.co</title><meta name=\"title\" content=\"Full Time Jobs – Find 24,731 Full Time Job Vacancies  | apna.co\"/><meta name=\"description\" content=\"25-Aug-2023 – Apply for 24,731 Full Time Jobs on apna. Register for Free &amp; Find ✓ Online ✓ Work from Home ✓ Freshers ✓ Women Job Vacancies that are Full Time \"/><meta name=\"image\" content=\"https://apna.co/apna-time-icon.png\"/><link rel=\"canonical\" href=\"https://apna.co/jobs/fu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 1000 words of the website\n",
    "page_content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation a file and loading the page contents in it.\n",
    "\n",
    "with open('webpage.html','w') as f:\n",
    "    f.write(page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use BeautifulSoup to Parse and Extract the Information\n",
    "\n",
    "* Using BeautifulSoup Library to extract information of the web-page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=BeautifulSoup(page_content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the type of doc which will be beautifulSoup object.\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Full Time Jobs – Find 24,731 Full Time Job Vacancies  | apna.co</title>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the Title of the webpage\n",
    "doc.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Properties and Methods to Extract the Required Information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Function to grab all Jobs Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job(doc):\n",
    "    job_name=[]\n",
    "    for i in doc.find_all('div',class_='JobListCardstyles__JobTitle-ffng7u-7 cuaBGE'):\n",
    "        job_name.append(i.text)\n",
    "    return job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business Head',\n",
       " 'Gynecologist',\n",
       " 'Gynecologist',\n",
       " 'UI Developer',\n",
       " 'ASP.NET Developer',\n",
       " 'Pediatrician And Neonatologist',\n",
       " 'Freight Forwarder']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Function to  Grab the Name of Companies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  company(doc):\n",
    "    company_name=[]\n",
    "    for i in doc.find_all('div',class_='JobListCardstyles__JobCompany-ffng7u-8 gguURM'):\n",
    "        company_name.append(i.text)\n",
    "    return company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kalandoor Entertainments Private Limited',\n",
       " 'Villemed Healthcare',\n",
       " 'Bedi Hospital',\n",
       " 'CBL Solutions',\n",
       " 'Enix Software Private Limited',\n",
       " 'Bedi Hospital',\n",
       " 'Agraga Solutions']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the location of job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=doc.find('div',class_='JobListCardstyles__DisplayFlexCenter-ffng7u-10 fNeylV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"JobListCardstyles__DisplayFlexCenter-ffng7u-10 fNeylV\"><svg fill=\"none\" height=\"16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"><g clip-path=\"url(#a)\"><path clip-rule=\"evenodd\" d=\"M14 13.162V6.029a.81.81 0 0 0-.397-.69L8.515 2.147a.957.957 0 0 0-1.018 0l-5.1 3.182a.844.844 0 0 0-.397.7v7.134c0 .459.41.838.906.838h3.192V9.2h3.75V14h3.246c.497 0 .906-.379.906-.838Z\" fill=\"#8C8594\" fill-rule=\"evenodd\"></path></g><defs><clippath id=\"a\"><path d=\"M2 2h12v12H2z\" fill=\"#fff\"></path></clippath></defs></svg>  <!-- -->Elamakkara</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Function to Grab the Location of job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elamakkara',\n",
       " 'Bakhtiarpur',\n",
       " 'Sector 33D chandigarh',\n",
       " 'HITEC City',\n",
       " 'Parsik Shiv Mandir',\n",
       " 'Sector 33D chandigarh',\n",
       " 'Mahadevapura Cross']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def location(doc):\n",
    "    job_location=[]\n",
    "    for i in doc.find_all('div',class_='JobListCardstyles__DisplayFlexCenter-ffng7u-10 fNeylV')[::2]:\n",
    "        job_location.append(i.text.strip())\n",
    "    return job_location\n",
    "location(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Function to grab the Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary(doc):\n",
    "    salary_paid=[]\n",
    "    for i in doc.find_all('div',class_='JobListCardstyles__DisplayFlexCenter-ffng7u-10 fNeylV')[1:2]:\n",
    "        salary_paid.append(i.text.strip())\n",
    "    return salary_paid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, We Will Scrape the Multiple Pages of the Web-site using Functions\n",
    "\n",
    "* Here we will scrape the multiple pages of the website, so that we can collect the data of all jobs present in the website\n",
    "\n",
    "* For that we will create a Function Scrape_data() which will takes the page no as input as give us the data upto that pages.\n",
    "\n",
    "* Here we have used the .Extend() method will add the specified list elements to the end of current list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_data():\n",
    "    all_details={'Job-Title':[],'Company-Name':[],'Location':[],'Salary':[]}\n",
    "    for i in range(0,30):\n",
    "        url=f\"https://apna.co/jobs/full_time-jobs?page={i}&work_type=full_time\"\n",
    "        response=requests.get(url,headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'})\n",
    "        if response.status_code!=200:\n",
    "            raise Exception('failed to load page {}'.format(url))\n",
    "        doc=BeautifulSoup(response.text)\n",
    "        all_details['Job-Title'].extend(job(doc))\n",
    "        all_details['Company-Name'].extend(company(doc))\n",
    "        all_details['Location'].extend(location(doc))\n",
    "        all_details['Salary'].extend(salary(doc))\n",
    "    return all_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now We Will Import the Pandas Library and Store the Data in It\n",
    "\n",
    "* jobs_df variable will store the information in Pandas dataframe.\n",
    "* We will scrape the first 30 pages of the website.\n",
    "* 30 pages will give us 210 rows* 4  columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "jobs_df=pd.DataFrame.from_dict(scrap_data(),orient='index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Company-Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Head</td>\n",
       "      <td>Kalandoor Entertainments Private Limited</td>\n",
       "      <td>Elamakkara</td>\n",
       "      <td>₹1,00,000 - ₹1,49,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gynecologist</td>\n",
       "      <td>Villemed Healthcare</td>\n",
       "      <td>Bakhtiarpur</td>\n",
       "      <td>₹1,00,000 - ₹1,49,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gynecologist</td>\n",
       "      <td>Bedi Hospital</td>\n",
       "      <td>Sector 33D chandigarh</td>\n",
       "      <td>₹1,00,000 - ₹1,49,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UI Developer</td>\n",
       "      <td>CBL Solutions</td>\n",
       "      <td>HITEC City</td>\n",
       "      <td>₹80,000 - ₹1,40,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASP.NET Developer</td>\n",
       "      <td>Enix Software Private Limited</td>\n",
       "      <td>Parsik Shiv Mandir</td>\n",
       "      <td>₹30,000 - ₹1,30,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Chemical Engineer</td>\n",
       "      <td>Bhagwati Trading Company</td>\n",
       "      <td>Huda Sector 25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Brand Manager</td>\n",
       "      <td>Phifer India</td>\n",
       "      <td>Anna Nagar</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Your Car</td>\n",
       "      <td>S.D Planets School</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>GNR Solution</td>\n",
       "      <td>Lone Phata</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Agency Development Manager</td>\n",
       "      <td>Royals Career Solutions</td>\n",
       "      <td>Vimannagar</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Job-Title                              Company-Name  \\\n",
       "0                     Business Head  Kalandoor Entertainments Private Limited   \n",
       "1                      Gynecologist                       Villemed Healthcare   \n",
       "2                      Gynecologist                             Bedi Hospital   \n",
       "3                      UI Developer                             CBL Solutions   \n",
       "4                 ASP.NET Developer             Enix Software Private Limited   \n",
       "..                              ...                                       ...   \n",
       "205               Chemical Engineer                  Bhagwati Trading Company   \n",
       "206                   Brand Manager                              Phifer India   \n",
       "207           Business Data Analyst                                  Your Car   \n",
       "208  Business Development Executive                              GNR Solution   \n",
       "209      Agency Development Manager                   Royals Career Solutions   \n",
       "\n",
       "                  Location                 Salary  \n",
       "0               Elamakkara  ₹1,00,000 - ₹1,49,999  \n",
       "1              Bakhtiarpur  ₹1,00,000 - ₹1,49,999  \n",
       "2    Sector 33D chandigarh  ₹1,00,000 - ₹1,49,999  \n",
       "3               HITEC City    ₹80,000 - ₹1,40,000  \n",
       "4       Parsik Shiv Mandir    ₹30,000 - ₹1,30,000  \n",
       "..                     ...                    ...  \n",
       "205         Huda Sector 25                   None  \n",
       "206             Anna Nagar                   None  \n",
       "207     S.D Planets School                   None  \n",
       "208             Lone Phata                   None  \n",
       "209             Vimannagar                   None  \n",
       "\n",
       "[210 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now We Will Save Our Data in a .CSV Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.to_csv('jobs.csv' , index= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jobs.csv](https://i.imgur.com/fTgaXSR.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"dharmendradiwaker12/web-scraping-final-project-using-python\" on https://jovian.com\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.com/dharmendradiwaker12/web-scraping-final-project-using-python\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.com/dharmendradiwaker12/web-scraping-final-project-using-python'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(Project =\"web-scraping-project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* The Project was a web scraping project which composite the libraries and function to fatch the data in .csv format and then can be downloaded as excel file for further analysis.\n",
    "\n",
    "* We have used request and BeautifulSoup library to downloaded and scrao the web-pages respectively.\n",
    "\n",
    "* we used find() and find_all() mothods to find different tags required from the website.\n",
    "\n",
    "* then we created multiple functions to grab the below information.\n",
    "1. Job-Title\n",
    "2. Company-Name\n",
    "3. Location\n",
    "4. Salary\n",
    "\n",
    "* After scraping the multiple functions we store the data in Pandas dataframe which is a library.\n",
    "\n",
    "* Finally we convert the stored data into .CSV file and the downloaded as Excel.\n",
    "\n",
    "## Future Scope\n",
    "\n",
    "* We can dig more and collect more information job-wise mention below.\n",
    "1. Qualification \n",
    "2. Experience required\n",
    "3. Test\n",
    "\n",
    "## References \n",
    "\n",
    "* Website scraping https://apna.co/\n",
    "* beautifulSoup Document https://beautiful-soup-4.readthedocs.io/en/latest/\n",
    "* Extend and Append method https://www.geeksforgeeks.org/append-extend-python/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
